{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da03237b-025f-4e84-b919-2c75e5b792fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc84e7f1-3626-4669-9b73-264805af4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "DATASET_PATH = os.environ.get('DATASET_PATH',\"./data\")\n",
    "BATCH_SIZE = 512 if torch.cuda.is_available() else 64\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "772bd031-7ca3-4a2a-9763-be545348e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataLoader(pl.LightningDataModule):\n",
    "    def __init__(self,root,batch_size,num_workers):\n",
    "        super(MnistDataLoader,self).__init__()\n",
    "        self.root = root\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307),(0.3081))\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def prepare_data(self):\n",
    "        datasets.MNIST(root = self.root,train=True,download=True)\n",
    "        datasets.MNIST(root = self.root,train=False,download=True)\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_dataset = datasets.MNIST(root = self.root,train=True,download=False,transform = self.transform)\n",
    "            \n",
    "            # Define the proportions for the split\n",
    "            train_proportion = 0.8  # 80% for training\n",
    "            val_proportion = 0.2  # 20% for validation\n",
    "    \n",
    "            # Calculate the sizes of training and validation sets based on the proportions\n",
    "            train_size = int(train_proportion * len(train_dataset))\n",
    "            val_size = len(train_dataset) - train_size\n",
    "            \n",
    "            # Use random_split to split the dataset\n",
    "            self.train_dataset, self.val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.test_dataset =  datasets.MNIST(root = self.root,train=False,download=False,transform = self.transform)\n",
    "            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(dataset=self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=self.num_workers,pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(dataset=self.val_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers,pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(dataset=self.test_dataset,batch_size=self.batch_size,shuffle=False,num_workers=self.num_workers,pin_memory=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4b36fe-0270-4d72-b4c2-c7c2d090ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MnistDataLoader(DATASET_PATH,BATCH_SIZE,NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1f19dc-b5f9-4ce7-887e-c2f8fc7e79da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sanity Check\n",
    "ds.prepare_data()\n",
    "ds.setup('fit')\n",
    "dataloader = ds.train_dataloader()\n",
    "\n",
    "\n",
    "# Create a dictionary to store one image per class\n",
    "class_images = {}\n",
    "\n",
    "# Iterate over the dataset and store one image per class\n",
    "for image, label in ds.train_dataset:\n",
    "    if label not in class_images:\n",
    "        class_images[label] = image\n",
    "        if len(class_images) == 10:  # Stop after storing one image per class\n",
    "            break\n",
    "\n",
    "# Display the images from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "for i, (label, image) in enumerate(class_images.items()):\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(image.squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Class: {label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "132c55eb-9c7a-4071-9822-1fdbf74bb2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def _block(in_feature, out_feature, normalize=True):\n",
    "            layers = [nn.Linear(in_feature, out_feature)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feature,0.8))\n",
    "            layers.append(nn.LeakyReLU(0.01))\n",
    "            return layers\n",
    "\n",
    "        self.g_model = nn.Sequential(\n",
    "            *_block(latent_dim, 128, normalize=False),\n",
    "            *_block(128, 256),\n",
    "            *_block(256, 512),\n",
    "            *_block(512, 1024),\n",
    "            nn.Linear(1024, img_shape),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.g_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20575575-980a-4ef5-a92c-f01d8c8f046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_feature):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.d_model = nn.Sequential(\n",
    "                                 nn.Linear(in_feature,512),\n",
    "                                 nn.LeakyReLU(negative_slope=0.2),\n",
    "                                 nn.Linear(512,256),\n",
    "                                 nn.LeakyReLU(0.2),\n",
    "                                 nn.Linear(256,1),\n",
    "                                 nn.Sigmoid())\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.d_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70a1e4e2-b666-4fb0-8225-50408da6a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def __init__(self,latent_dim,img_shape,lr,b1,b2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.generator = Generator(latent_dim,img_shape).apply(self.weights_init)\n",
    "        self.discriminator = Discriminator(img_shape).apply(self.weights_init)\n",
    "\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def forward(self,z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self,y_hat,y):\n",
    "        return nn.functional.binary_cross_entropy(y_hat,y)\n",
    "\n",
    "\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        imgs, _ = batch \n",
    "\n",
    "        # sample noise \n",
    "        z = torch.randn(imgs.shape[0],self.hparams.latent_dim).type_as(imgs)\n",
    "\n",
    "\n",
    "        # ground truth \n",
    "        label_one = torch.ones(imgs.shape[0],1).type_as(imgs)\n",
    "        label_zero = torch.zeros(imgs.shape[0],1).type_as(imgs)\n",
    "\n",
    "        # Get optimizers\n",
    "        g_opt, d_opt = self.optimizers()\n",
    "\n",
    "        # Train Generator\n",
    "        self.toggle_optimizer(g_opt)\n",
    "\n",
    "        self.generated_img = self(z)\n",
    "\n",
    "        #log \n",
    "        if not batch_idx % 100:\n",
    "            sample_imgs = self.generated_img[:6]\n",
    "            grid = torchvision.utils.make_grid(sample_imgs.view(-1,1,28,28))\n",
    "            self.logger.experiment.add_image('generated_images',grid,self.current_epoch)\n",
    "        \n",
    "        g_loss = self.adversarial_loss(self.discriminator(self.generated_img),label_one)\n",
    "        self.log('g_loss',g_loss,prog_bar=True)\n",
    "\n",
    "        self.manual_backward(g_loss)\n",
    "        g_opt.step()\n",
    "        g_opt.zero_grad()\n",
    "        self.untoggle_optimizer(g_opt)\n",
    "\n",
    "\n",
    "        # Train discriminator\n",
    "        self.toggle_optimizer(d_opt)\n",
    "        # how well it can be label as real\n",
    "        real_loss = self.adversarial_loss(self.discriminator(imgs.view(imgs.shape[0],-1)),label_one)\n",
    "        # how well it can be label as fake\n",
    "        fake_loss = self.adversarial_loss(self.discriminator(self.generated_img.detach()),label_zero)\n",
    "\n",
    "        d_loss = (real_loss + fake_loss)/2\n",
    "        self.log('d_loss',d_loss,prog_bar=True)\n",
    "\n",
    "        self.manual_backward(d_loss)\n",
    "        d_opt.step()\n",
    "        d_opt.zero_grad()\n",
    "        self.untoggle_optimizer(d_loss)\n",
    "\n",
    "\n",
    "    def validation_step(self,batch):\n",
    "        imgs, _ = batch\n",
    "        validation_noise = torch.randn(8,self.hparams.latent_dim).type_as(imgs)\n",
    "                    \n",
    "        #log \n",
    "        sample_imgs = self(validation_noise)\n",
    "        grid = torchvision.utils.make_grid(sample_imgs.view(-1,1,28,28))\n",
    "        self.logger.experiment.add_image('Validation_z',grid,self.current_epoch)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        g_opt = torch.optim.AdamW(self.generator.parameters(),lr=self.hparams.lr, betas=[self.hparams.b1,self.hparams.b2])\n",
    "        d_opt = torch.optim.AdamW(self.discriminator.parameters(),lr=self.hparams.lr, betas=[self.hparams.b1,self.hparams.b2])            \n",
    "            \n",
    "        return [g_opt,d_opt], []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ca491a-ebfc-4700-b6b4-213654e44dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim, img_shape, lr, b1, b2 = 100, 1*28*28, 2e-4, 0.5, 0.999\n",
    "model = GAN(latent_dim, img_shape, lr, b1,b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46d3619c-3d3e-4870-8722-7e1831686d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bd1bd24-2b35-4912-82c8-567eb4893f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba6fee94a894517b59631632bf40e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "Exception in thread Thread-741 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/pranav-pc/.env/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pranav-pc/.env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 55, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/home/pranav-pc/.env/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py\", line 32, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/pranav-pc/.env/lib/python3.12/site-packages/torch/multiprocessing/reductions.py\", line 496, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/resource_sharer.py\", line 58, in detach\n",
      "    return reduction.recv_handle(conn)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/reduction.py\", line 189, in recv_handle\n",
      "    return recvfds(s, 1)[0]\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/multiprocessing/reduction.py\", line 157, in recvfds\n",
      "    msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:252\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 252\u001b[0m             batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanual_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/manual.py:94\u001b[0m, in \u001b[0;36m_ManualOptimization.run\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mStopIteration\u001b[39;00m):  \u001b[38;5;66;03m# no loop to break at this level\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/manual.py:114\u001b[0m, in \u001b[0;36m_ManualOptimization.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m kwargs  \u001b[38;5;66;03m# release the batch from memory\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 55\u001b[0m, in \u001b[0;36mGAN.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# how well it can be label as real\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m real_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madversarial_loss(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,label_one)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# how well it can be label as fake\u001b[39;00m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(min_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      2\u001b[0m                         max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m ,\n\u001b[1;32m      3\u001b[0m                         \u001b[38;5;66;03m# precision='16-mixed',\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m                         log_every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      8\u001b[0m                     )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(min_epochs=1,\n",
    "                        max_epochs=2000 ,\n",
    "                        # precision='16-mixed',\n",
    "                        enable_model_summary=False,\n",
    "                        # callbacks=[pl.callbacks.EarlyStopping('d_loss',min_delta=0.0,patience=5)],\n",
    "                        enable_checkpointing  = True,\n",
    "                        log_every_n_steps=10\n",
    "                    )\n",
    "trainer.fit(model,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12b771-5d9d-4140-95d7-26ed2cdaae0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcfd9fe-0b63-400b-99e5-7f233fb1b4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626b950-9399-4172-9422-bd92b191ce00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-lab",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
